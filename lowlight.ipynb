{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low light face enhancement with Retinex-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this project is for low light face enhancement\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all parameters\n",
    "inw = 600   #input image width\n",
    "inh = 400\n",
    "inc = 3\n",
    "lr = 0.01 #learning rate\n",
    "batch = 5 #batch number, better a factor of total image number\n",
    "epoch = 100\n",
    "dk1 = 6 #decom-net kernel number for conv1\n",
    "dk2 = 12\n",
    "dk3 = 24\n",
    "dk4 = 48\n",
    "dk5 = 24\n",
    "dk6 = 12\n",
    "dk7 = 6\n",
    "ek1 = 3 #enhance-net kernel number for conv1\n",
    "ek2 = 3\n",
    "ek3 = 3\n",
    "lamda00=1   \n",
    "lamda01=0.01\n",
    "lamda10=0.01\n",
    "lamda11=1\n",
    "lamda_g= -10\n",
    "lamda_ir = 0.001\n",
    "lamda_is = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.define local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "    target = tf.image.resize_nearest_neighbor(source, (newHt,newWid))\n",
    "    return target\n",
    "\n",
    "'''\n",
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "     #souce: 4D tensor, 4D=[batch,height,width,channel]\n",
    "     #newHt: target Height\n",
    "     #newWid: target Width\n",
    "    width  = int(source.shape[2])\n",
    "    height = int(source.shape[1])\n",
    "    print(\"source shape:\",source.shape)    \n",
    "    newX = tf.Variable(tf.zeros(shape=[source.shape[0],newHt+1,1,source.shape[-1]]), name=\"tempX\")\n",
    "    for x in range(0, newWid):  \n",
    "        newY = tf.Variable(tf.zeros(shape=[source.shape[0],1,1,source.shape[-1]]), name=\"tempY\")        \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            sourceSlice = tf.slice(source,[0,srcY,srcX,0],[source.shape[0],1,1,source.shape[-1]])\n",
    "            newY = tf.concat([newY,sourceSlice],axis=1)\n",
    "        newX = tf.concat([newX,newY],axis=2)\n",
    "    target = tf.slice(newX,[0,1,1,0],[source.shape[0],newHt,newWid,source.shape[-1]])\n",
    "    print(\"target shape:\",target.shape)\n",
    "    return target\n",
    "'''\n",
    "\n",
    "def nearestNeighborScaling3D( source, newHt,newWid):\n",
    "    '''\n",
    "     souce: 3D array, 3D=[height,width,channel]\n",
    "     newHt: target Height\n",
    "     newWid: target Width\n",
    "    '''\n",
    "    width  = int(source.shape[1])\n",
    "    height = int(source.shape[0])\n",
    "    target = np.zeros((newHt,newWid,source.shape[-1]),dtype = np.float32)\n",
    "    for x in range(0, newWid):  \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            target[y,x,:] = source[srcY,srcX,:]\n",
    "    return target\n",
    "\n",
    "\n",
    "def input_parser(img_path):\n",
    "    # read the img from file\n",
    "    img_file = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_image(img_file, channels=3)\n",
    "    return img_decoded\n",
    "\n",
    "def input_parser_pair(img_path0,img_path1):\n",
    "    # read the img from file\n",
    "    img_file0 = tf.read_file(img_path0)\n",
    "    img_file1 = tf.read_file(img_path1)\n",
    "    img_decoded0 = tf.image.decode_image(img_file0,dtype=tf.float32, channels=3)/255.0\n",
    "    img_decoded1 = tf.image.decode_image(img_file1,dtype=tf.float32, channels=3)/255.0\n",
    "    return img_decoded0,img_decoded1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build network\n",
    "#with tf.Graph().as_default():\n",
    "with tf.name_scope('input_image'):\n",
    "    xlow = tf.placeholder(tf.float32, shape=[batch,inh,inw,inc],name = 'input_low')   #input low light image\n",
    "    print(xlow.shape)\n",
    "    xnorm = tf.placeholder(tf.float32, shape=[batch, inh, inw, inc], name='input_norm') #input norm light image\n",
    "        \n",
    "with tf.variable_scope(\"decom\", reuse=tf.AUTO_REUSE):  #define weight and bias\n",
    "    #shared weight between low light Decom-net and normal light Decom-net\n",
    "    weight1 = tf.get_variable(name='w1', shape=[3,3,3,dk1],  initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight2 = tf.get_variable(name='w2', shape=[3,3,dk1,dk2], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight3 = tf.get_variable(name='w3', shape=[3,3,dk2,dk3],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight4 = tf.get_variable(name='w4', shape=[3,3,dk3,dk4],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight5 = tf.get_variable(name='w5', shape=[3,3,dk4,dk5],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight6 = tf.get_variable(name='w6', shape=[3,3,dk5,dk6],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight7 = tf.get_variable(name='w7', shape=[3,3,dk6,dk7], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    #bias for low light conv\n",
    "    lowb1 = tf.get_variable(\"lowb1\", shape=[dk1], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb2 = tf.get_variable(\"lowb2\", shape=[dk2], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb3 = tf.get_variable(\"lowb3\", shape=[dk3], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb4 = tf.get_variable(\"lowb4\", shape=[dk4], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb5 = tf.get_variable(\"lowb5\", shape=[dk5], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb6 = tf.get_variable(\"lowb6\", shape=[dk6], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb7 = tf.get_variable(\"lowb7\", shape=[dk7], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    #bias for normal light conv\n",
    "    normb1 = tf.get_variable(\"normb1\", shape=[dk1], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb2 = tf.get_variable(\"normb2\", shape=[dk2], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb3 = tf.get_variable(\"normb3\", shape=[dk3], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb4 = tf.get_variable(\"normb4\", shape=[dk4], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb5 = tf.get_variable(\"normb5\", shape=[dk5], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb6 = tf.get_variable(\"normb6\", shape=[dk6], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb7 = tf.get_variable(\"normb7\", shape=[dk7], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "        \n",
    "with tf.name_scope('decom_net_low'):\n",
    "    lowcc1 = tf.nn.conv2d(xlow, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "    lowconv1 = tf.nn.relu(lowcc1 + lowb1, name=\"conv1\")\n",
    "    print(\"low conv1 shape:\",lowconv1.shape)\n",
    "        \n",
    "    lowcc2 = tf.nn.conv2d(lowcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    lowconv2 = tf.nn.relu(lowcc2 + lowb2, name=\"conv2\")        \n",
    "    #print(\"low conv2 shape:\",lowconv2.shape)\n",
    "            \n",
    "    lowcc3 = tf.nn.conv2d(lowcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    lowconv3 = tf.nn.relu(lowcc3 + lowb3, name=\"conv3\")  \n",
    "    #print(\"low conv3 shape:\",lowconv3.shape)\n",
    "        \n",
    "    lowcc4 = tf.nn.conv2d(lowcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    lowconv4 = tf.nn.relu(lowcc4 + lowb4, name=\"conv4\")  \n",
    "    #print(\"low conv4 shape:\",lowconv4.shape) \n",
    "\n",
    "    lowcc5 = tf.nn.conv2d(lowcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    lowconv5 = tf.nn.relu(lowcc5 + lowb5, name=\"conv5\")  \n",
    "    #print(\"low conv5 shape:\",lowconv5.shape)\n",
    "        \n",
    "    lowcc6 = tf.nn.conv2d(lowcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    lowconv6 = tf.nn.relu(lowcc6 + lowb6, name=\"conv6\")  \n",
    "    #print(\"low conv6 shape:\",lowconv6.shape)\n",
    "        \n",
    "    lowcc7 = tf.nn.conv2d(lowcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    lowconv7 = tf.nn.sigmoid(lowcc7 + lowb7, name=\"conv7\") \n",
    "    print(\"low conv7 shape:\",lowconv7.shape)\n",
    "\n",
    "with tf.name_scope('decom_net_normal'):\n",
    "    normcc1 = tf.nn.conv2d(xnorm, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "    normconv1 = tf.nn.relu(normcc1 + normb1, name=\"conv1\")\n",
    "        \n",
    "    normcc2 = tf.nn.conv2d(normcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    normconv2 = tf.nn.relu(normcc2 + normb2, name=\"conv2\")        \n",
    "        \n",
    "    normcc3 = tf.nn.conv2d(normcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    normconv3 = tf.nn.relu(normcc3 + normb3, name=\"conv3\")  \n",
    "        \n",
    "    normcc4 = tf.nn.conv2d(normcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    normconv4 = tf.nn.relu(normcc4 + normb4, name=\"conv4\")  \n",
    "        \n",
    "    normcc5 = tf.nn.conv2d(normcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    normconv5 = tf.nn.relu(normcc5 + normb5, name=\"conv5\")  \n",
    "        \n",
    "    normcc6 = tf.nn.conv2d(normcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    normconv6 = tf.nn.relu(normcc6 + normb6, name=\"conv6\")  \n",
    "        \n",
    "    normcc7 = tf.nn.conv2d(normcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    normconv7 = tf.nn.sigmoid(normcc7 + normb7, name=\"conv7\")  \n",
    "    print(\"normal conv7 shape:\",normconv7.shape)\n",
    "        \n",
    "with tf.name_scope('decom_output_low'):\n",
    "    Ilow = tf.slice(lowconv7,[0,0,0,0],[batch,-1,-1,int(dk7/2)],name=\"Ilow_output\")   #output I low image\n",
    "    Rlow = tf.slice(lowconv7,[0,0,0,int(dk7/2)],[batch,-1,-1,int(dk7/2)],name='Rlow_output') #output R low image        \n",
    "    \n",
    "with tf.name_scope('decom_output_norm'):\n",
    "    Inorm = tf.slice(normconv7,[0,0,0,0],[batch,-1,-1,int(dk7/2)],name=\"Inorm_output\")   #output I norm image\n",
    "    Rnorm = tf.slice(normconv7,[0,0,0,int(dk7/2)],[batch,-1,-1,int(dk7/2)],name='Rnorm_output') #output R norm image \n",
    "    print(\"Ilow shape:\",Ilow.shape)\n",
    "    print(\"Rlow shape:\",Rlow.shape)\n",
    "    print(\"Inorm shape:\",Inorm.shape)\n",
    "    print(\"Rnorm shape:\",Rnorm.shape) \n",
    "\n",
    "with tf.name_scope('enhance_net'):\n",
    "    with tf.name_scope(\"encoder_decoder\"):\n",
    "        encconv1  =  tf.layers.conv2d(inputs=Ilow,filters=ek1,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample1')\n",
    "        encconv2  =  tf.layers.conv2d(inputs=encconv1,filters=ek2,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample2')\n",
    "        encconv3  =  tf.layers.conv2d(inputs=encconv2,filters=ek3,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample3')\n",
    "        \n",
    "        #import types\n",
    "        #print(type(normconv7))\n",
    "        conv3_shape = encconv3.shape\n",
    "        upsample1 = nearestNeighborScaling4D(encconv3, int(conv3_shape[1]*2),int(conv3_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv1  =  tf.layers.conv2d(inputs=upsample1,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv1')\n",
    "        upresidual1 =  tf.add(upconv1,encconv2,name=\"upres1\")\n",
    "        \n",
    "        upresidual1_shape = upresidual1.shape\n",
    "        upsample2 = nearestNeighborScaling4D(upresidual1, int(upresidual1_shape[1]*2),int(upresidual1_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv2  =  tf.layers.conv2d(inputs=upsample2,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv2')\n",
    "        upresidual2 =  tf.add(upconv2,encconv1,name=\"upres2\")\n",
    "        \n",
    "        upresidual2_shape = upresidual2.shape\n",
    "        upsample3 = nearestNeighborScaling4D(upresidual2, int(upresidual2_shape[1]*2),int(upresidual2_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv3  =  tf.layers.conv2d(inputs=upsample3,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv3')\n",
    "        upresidual3 =  tf.add(upconv3,Ilow,name=\"upres3\")  \n",
    "        print(\"upresidual3 shape:\",upresidual3.shape)\n",
    "        \n",
    "    with tf.name_scope(\"upsample_concat\"):\n",
    "        upresidual3_shape = upresidual3.shape\n",
    "        preconcat1 = nearestNeighborScaling4D(upresidual1, int(upresidual3_shape[1]),int(upresidual3_shape[2])) \n",
    "        preconcat2 = nearestNeighborScaling4D(upresidual2, int(upresidual3_shape[1]),int(upresidual3_shape[2])) \n",
    "        preconcat3 = upresidual3\n",
    "        concat = tf.concat([preconcat1,preconcat2,preconcat3],axis=3)  #concat on channel direction\n",
    "        print(\"concat shape:\",concat.shape)\n",
    "        \n",
    "    with tf.name_scope('reconstruct_illumination'):\n",
    "        resizeconv = tf.layers.conv2d(inputs=concat,filters=inc,kernel_size=[1,1],strides=[1,1],padding='same',activation=tf.nn.relu,name='resize_conv')\n",
    "        reconI = tf.layers.conv2d(inputs=resizeconv,filters=inc,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='reconstruct_illumination')\n",
    "        print(\"reconI shape:\",reconI.shape)\n",
    "        \n",
    "with tf.name_scope(\"reconstruct_Image\"):\n",
    "    denoiseR = Rlow\n",
    "    reconImage = tf.multiply(reconI,denoiseR,name=\"reconstruct_Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decom-net loss function\n",
    "Lrecon00 = tf.abs(tf.multiply(Ilow,Rlow)-xlow)\n",
    "Lrecon01 = tf.abs(tf.multiply(Ilow,Rnorm)-xlow)\n",
    "Lrecon10 = tf.abs(tf.multiply(Inorm,Rlow)-xnorm)\n",
    "Lrecon11 = tf.abs(tf.multiply(Inorm,Rnorm)-xnorm)\n",
    "Lrecon_decom = tf.reduce_mean(lamda00*Lrecon00+lamda01*Lrecon01+lamda10*Lrecon10+lamda11*Lrecon11)\n",
    "Lir_decom = tf.reduce_mean(tf.abs(Rlow-Rnorm))\n",
    "\n",
    "Lis_decom = tf.reduce_mean(tf.image.image_gradients(Ilow)[0]*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[0])) + \\\n",
    "            tf.reduce_mean(tf.image.image_gradients(Ilow)[1]*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[1])) + \\\n",
    "            tf.reduce_mean(tf.image.image_gradients(Inorm)[0]*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[0])) + \\\n",
    "            tf.reduce_mean(tf.image.image_gradients(Inorm)[1]*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[1]))\n",
    "Ldecom = Lrecon_decom + lamda_ir*Lir_decom + lamda_is*Lis_decom\n",
    "\n",
    "\n",
    "##enhance-net loss function\n",
    "Lrecon_enh = tf.reduce_mean(reconI*denoiseR-xnorm)\n",
    "Lis_enh = tf.reduce_mean(tf.image.image_gradients(reconI)[0]*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[0])) + \\\n",
    "          tf.reduce_mean(tf.image.image_gradients(reconI)[1]*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[1]))\n",
    "Lenh = Lrecon_enh + lamda_is*Lis_enh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.generate dataset and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get file name list\n",
    "low_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\low\\\\*.png\"\n",
    "norm_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\high\\\\*.png\"\n",
    "low_names = tf.train.match_filenames_once(low_dir) #return all matched names, a variable\n",
    "norm_names = tf.train.match_filenames_once(norm_dir) \n",
    "low_list = tf.Variable(\"\",dtype=tf.string) \n",
    "norm_list = tf.Variable(\"\",dtype=tf.string) \n",
    "with tf.Session() as sess:    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    filesfind0,filesfind1 = sess.run((low_names,norm_names))\n",
    "    f_string0 = [\"\"]*filesfind0.shape[0]\n",
    "    f_string1 = [\"\"]*filesfind1.shape[0]\n",
    "    assert filesfind0.shape[0]==filesfind1.shape[0]\n",
    "    for i in range(0,filesfind0.shape[0]):\n",
    "        f_string0[i] = filesfind0[i].decode()  #from byte to string\n",
    "        f_string1[i] = filesfind1[i].decode()\n",
    "    low_list = f_string0\n",
    "    norm_list = f_string1\n",
    "\n",
    "print(\"low light file:\",low_list[0])\n",
    "print(\"low light file number:\",len(low_list))\n",
    "print(\"norm light file number:\",len(norm_list))\n",
    "\n",
    "#build data set\n",
    "total_train_images = len(low_list)\n",
    "tr_data = tf.data.Dataset.from_tensor_slices((low_list,norm_list))   #buid dataset from file name\n",
    "tr_data = tr_data.map(input_parser_pair) #map file name to file\n",
    "tr_data = tr_data.shuffle(buffer_size=total_train_images).batch(batch).repeat(epoch) #form batch, pack 1 batch into 1 element\n",
    "\n",
    "#get iterator\n",
    "iterator = tr_data.make_initializable_iterator() #make iterator\n",
    "next_element = iterator.get_next()  #next batch actually\n",
    "training_init_op = iterator.make_initializer(tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.begin training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 train decom-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run training\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(Ldecom)\n",
    "i=0\n",
    "j=0\n",
    "with tf.Session() as sess:\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            i +=1\n",
    "            elem = sess.run(next_element)  #get next batch input image\n",
    "            feed = {\n",
    "                xlow:elem[0],\n",
    "                xnorm:elem[1]\n",
    "            }\n",
    "            sess.run(optimizer,feed_dict=feed)\n",
    "            if i%(485/5)==0:\n",
    "                j +=1\n",
    "                print(\"epoch:\",j)\n",
    "            if i%20 == 0:\n",
    "                print('loss for batch ',i,\" is \", sess.run(Ldecom, feed_dict=feed))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training dataset.\")\n",
    "            break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
