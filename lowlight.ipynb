{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low light face enhancement with Retinex-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#this project is for low light face enhancement\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all parameters\n",
    "load_pretrain = 1\n",
    "auto_checkpoint = 0\n",
    "seed = 2018\n",
    "patch = 48 \n",
    "lr = 0.001 #learning rate\n",
    "batch = 15 #batch number, better a factor of total image number\n",
    "epoch = 100 #total epoch for both training Decom-Net + Enhance-Net\n",
    "dk1 = 64 #decom-net kernel number for conv1\n",
    "dk2 = 64\n",
    "dk3 = 64\n",
    "dk4 = 64\n",
    "dk5 = 64\n",
    "dk6 = 64\n",
    "dk7 = 4\n",
    "\n",
    "ek1 = 64 #enhance-net kernel number for conv1\n",
    "ek2 = 64\n",
    "ek3 = 64\n",
    "rk = 64 #resize layer kernel numebr\n",
    "\n",
    "random.seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.define local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#test array_to_image function\\nim = np.asarray(Image.open(\"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\high\\\\9.png\")).reshape((1, 400, 600, 3))/255.0\\narray_to_image(im,0,\"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\myresult\\\\train\" , \"HH\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "    target = tf.image.resize_nearest_neighbor(source, (newHt,newWid))\n",
    "    return target\n",
    "\n",
    "'''\n",
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "     #souce: 4D tensor, 4D=[batch,height,width,channel]\n",
    "     #newHt: target Height\n",
    "     #newWid: target Width\n",
    "    width  = int(source.shape[2])\n",
    "    height = int(source.shape[1])\n",
    "    print(\"source shape:\",source.shape)    \n",
    "    newX = tf.Variable(tf.zeros(shape=[source.shape[0],newHt+1,1,source.shape[-1]]), name=\"tempX\")\n",
    "    for x in range(0, newWid):  \n",
    "        newY = tf.Variable(tf.zeros(shape=[source.shape[0],1,1,source.shape[-1]]), name=\"tempY\")        \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            sourceSlice = tf.slice(source,[0,srcY,srcX,0],[source.shape[0],1,1,source.shape[-1]])\n",
    "            newY = tf.concat([newY,sourceSlice],axis=1)\n",
    "        newX = tf.concat([newX,newY],axis=2)\n",
    "    target = tf.slice(newX,[0,1,1,0],[source.shape[0],newHt,newWid,source.shape[-1]])\n",
    "    print(\"target shape:\",target.shape)\n",
    "    return target\n",
    "\n",
    "def nearestNeighborScaling3D( source, newHt,newWid):\n",
    "     #souce: 3D array, 3D=[height,width,channel]\n",
    "     #newHt: target Height\n",
    "     #newWid: target Width\n",
    "    width  = int(source.shape[1])\n",
    "    height = int(source.shape[0])\n",
    "    target = np.zeros((newHt,newWid,source.shape[-1]),dtype = np.float32)\n",
    "    for x in range(0, newWid):  \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            target[y,x,:] = source[srcY,srcX,:]\n",
    "    return target\n",
    "'''\n",
    "\n",
    "# random data augmentation\n",
    "def data_aug(image0, image1):\n",
    "    #total 4*2*2 = 16 choice\n",
    "    mode = np.random.randint(2,size=3)   #mode is an array, 3 elements\n",
    "    rotate = random.randint(0,4)\n",
    "    new_image0 = image0\n",
    "    new_image1 = image1\n",
    "    if mode[0]==1:  #rotate 0/90/180/270\n",
    "        new_image0 = tf.image.rot90(new_image0,k=rotate)\n",
    "        new_image1 = tf.image.rot90(new_image1,k=rotate)\n",
    "    if mode[1]==1: #flip left/right\n",
    "        new_image0 = tf.image.flip_left_right(new_image0)\n",
    "        new_image1 = tf.image.flip_left_right(new_image1)\n",
    "    if mode[2]==1:  #flip up/down\n",
    "        new_image0 = tf.image.flip_up_down(new_image0)\n",
    "        new_image1 = tf.image.flip_up_down(new_image1)\n",
    "    return new_image0,new_image1 \n",
    "\n",
    "def patch_gen_do(image0,image1):\n",
    "    imh = tf.shape(image0)[1]\n",
    "    imw = tf.shape(image0)[2]\n",
    "    image0_patch = tf.Variable(lambda:tf.zeros(shape=[1,patch,patch,3]), name=\"image_patch0\")\n",
    "    image1_patch = tf.Variable(lambda:tf.zeros(shape=[1,patch,patch,3]), name=\"image_patch1\")\n",
    "    for i in range(batch):\n",
    "        randh =random.randint(0,400-patch) #random.randint(0,imh-patch)\n",
    "        randw =random.randint(0,600-patch) #random.randint(0,imw-patch)\n",
    "        image0_temp = tf.slice(image0,[i,randh,randw,0],[1,patch,patch,-1]) #get slice\n",
    "        image1_temp = tf.slice(image1,[i,randh,randw,0],[1,patch,patch,-1])\n",
    "        image0_temp,image1_temp = data_aug(image0_temp,image1_temp) #dat augmentation\n",
    "        image0_patch = tf.concat([image0_patch,image0_temp],axis=0)\n",
    "        image1_patch = tf.concat([image1_patch,image1_temp],axis=0)\n",
    "    image0_patch = tf.slice(image0_patch,[1,0,0,0],[-1,-1,-1,-1])\n",
    "    image1_patch = tf.slice(image1_patch,[1,0,0,0],[-1,-1,-1,-1])\n",
    "    return image0_patch,image1_patch    \n",
    "\n",
    "def patch_gen_bypass(image0,image1):\n",
    "    in_batch = tf.shape(image0)[0]\n",
    "    image0_slice = tf.slice(image0,[0,0,0,0],[in_batch,-1,-1,-1])\n",
    "    image1_slice = tf.slice(image1,[0,0,0,0],[in_batch,-1,-1,-1])\n",
    "    return image0_slice,image1_slice    \n",
    "\n",
    "#generate random patch with data augmentation\n",
    "#def patch_gen(image0,image1,bypass_patch_gen): #can't use if/else inside\n",
    "\n",
    "\n",
    "#extend channel form 3 to 4, by adding max_in_channel\n",
    "def channel_extension(image0,image1):\n",
    "    image0_ex = tf.reduce_max(image0, axis=3, keepdims=True)\n",
    "    image1_ex = tf.reduce_max(image1, axis=3, keepdims=True)\n",
    "    image0_new = tf.concat([image0_ex,image0],axis=3)  ##?? the sequence?\n",
    "    image1_new = tf.concat([image1_ex,image1],axis=3)\n",
    "    return image0_new,image1_new\n",
    "    \n",
    "\n",
    "#from original image pair --> input image pair, resize to 400*600\n",
    "def input_parser_pair(img_path0,img_path1):\n",
    "    # read the img from file\n",
    "    img_file0 = tf.read_file(img_path0)\n",
    "    img_file1 = tf.read_file(img_path1)\n",
    "    img_decoded0 = tf.image.decode_image(img_file0,dtype=tf.float32, channels=3) #3D tensor\n",
    "    img_decoded1 = tf.image.decode_image(img_file1,dtype=tf.float32, channels=3)\n",
    "    image_stack0 = tf.stack([img_decoded0],axis=0) #3D->4D\n",
    "    image_stack1 = tf.stack([img_decoded1],axis=0)\n",
    "    img0_resize = tf.image.resize_nearest_neighbor(image_stack0,[400,600]) #only support 4D input\n",
    "    img1_resize = tf.image.resize_nearest_neighbor(image_stack1,[400,600])\n",
    "    img0_resize_3D = (tf.squeeze(img0_resize)) #4D->3D\n",
    "    img1_resize_3D = (tf.squeeze(img1_resize))\n",
    "    return img0_resize_3D,img1_resize_3D\n",
    "\n",
    "\n",
    "#input 4D array to batch number of images,saved to file\n",
    "def array_to_image(inarray,epoch, fpath, prefix=\"\"):\n",
    "    batch = inarray.shape[0]\n",
    "    if (inarray.shape[3]==3): #RGB\n",
    "        for i in range(batch):\n",
    "            image_pre = np.uint8(inarray[i,:,:,:]*255)\n",
    "            im = Image.fromarray(image_pre,mode='RGB')\n",
    "            im.save(os.path.join(fpath, prefix+'epoch'+str(epoch)+'img'+str(i)+'.png'),'png')\n",
    "    elif (inarray.shape[3]==1): #gray image, for I\n",
    "        for i in range(batch):\n",
    "            image_pre = np.uint8(inarray[i,:,:,0]*255)\n",
    "            im = Image.fromarray(image_pre,mode='L')\n",
    "            im.save(os.path.join(fpath, prefix+'epoch'+str(epoch)+'img'+str(i)+'.png'),'png')\n",
    "\n",
    "'''\n",
    "#test array_to_image function\n",
    "im = np.asarray(Image.open(\"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\high\\\\9.png\")).reshape((1, 400, 600, 3))/255.0\n",
    "array_to_image(im,0,\"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\myresult\\\\train\" , \"HH\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low conv7 shape: (?, ?, ?, 4)\n",
      "normal conv7 shape: (?, ?, ?, 4)\n",
      "Ilow shape: (?, ?, ?, 1)\n",
      "Rlow shape: (?, ?, ?, 3)\n",
      "Inorm shape: (?, ?, ?, 1)\n",
      "Rnorm shape: (?, ?, ?, 3)\n",
      "upresidual3 shape: (?, ?, ?, 64)\n",
      "concat shape: (?, ?, ?, 192)\n",
      "reconI shape: (?, ?, ?, 1)\n"
     ]
    }
   ],
   "source": [
    "#build network\n",
    "with tf.name_scope('input_image'):\n",
    "    imlow = tf.placeholder(tf.float32, shape=[None,None,None,3],name = 'input_low')   #input low light image\n",
    "    imnorm = tf.placeholder(tf.float32, shape=[None,None,None,3], name='input_norm') #input norm light image\n",
    "    bypass_patch_gen = tf.placeholder(tf.bool)\n",
    "    xlow_pre, xnorm_pre = tf.cond(bypass_patch_gen,lambda:patch_gen_bypass(imlow,imnorm),lambda:patch_gen_do(imlow,imnorm))\n",
    "    xlow, xnorm = channel_extension(xlow_pre,xnorm_pre) #channel extention 3->4 \n",
    "       \n",
    "with tf.variable_scope(\"decom\", reuse=tf.AUTO_REUSE):  #define weight and bias\n",
    "    #shared weight between low light Decom-net and normal light Decom-net\n",
    "    weight1 = tf.get_variable(name='w1', shape=[3,3,4,dk1],  initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight2 = tf.get_variable(name='w2', shape=[3,3,dk1,dk2], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight3 = tf.get_variable(name='w3', shape=[3,3,dk2,dk3],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight4 = tf.get_variable(name='w4', shape=[3,3,dk3,dk4],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight5 = tf.get_variable(name='w5', shape=[3,3,dk4,dk5],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight6 = tf.get_variable(name='w6', shape=[3,3,dk5,dk6],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight7 = tf.get_variable(name='w7', shape=[3,3,dk6,dk7], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "\n",
    "    #bias for normal light conv\n",
    "    b1 = tf.get_variable(\"b1\", shape=[dk1], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b2 = tf.get_variable(\"b2\", shape=[dk2], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b3 = tf.get_variable(\"b3\", shape=[dk3], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b4 = tf.get_variable(\"b4\", shape=[dk4], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b5 = tf.get_variable(\"b5\", shape=[dk5], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b6 = tf.get_variable(\"b6\", shape=[dk6], initializer=tf.constant_initializer(0.001), dtype=tf.float32)\n",
    "    b7 = tf.get_variable(\"b7\", shape=[dk7], initializer=tf.constant_initializer(0.001), dtype=tf.float32)    \n",
    "    \n",
    "with tf.name_scope('decom_net_low'):\n",
    "    lowcc1 = tf.nn.conv2d(xlow, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "        \n",
    "    lowcc2 = tf.nn.conv2d(lowcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    lowconv2 = tf.nn.relu(lowcc2 + b2, name=\"conv2\")        \n",
    "            \n",
    "    lowcc3 = tf.nn.conv2d(lowcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    lowconv3 = tf.nn.relu(lowcc3 + b3, name=\"conv3\")  \n",
    "        \n",
    "    lowcc4 = tf.nn.conv2d(lowcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    lowconv4 = tf.nn.relu(lowcc4 + b4, name=\"conv4\")  \n",
    "\n",
    "    lowcc5 = tf.nn.conv2d(lowcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    lowconv5 = tf.nn.relu(lowcc5 + b5, name=\"conv5\")  \n",
    "        \n",
    "    lowcc6 = tf.nn.conv2d(lowcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    lowconv6 = tf.nn.relu(lowcc6 + b6, name=\"conv6\")  \n",
    "        \n",
    "    lowcc7 = tf.nn.conv2d(lowcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    lowconv7 = tf.nn.sigmoid(lowcc7 + b7, name=\"conv7\") \n",
    "    print(\"low conv7 shape:\",lowconv7.shape)\n",
    "\n",
    "with tf.name_scope('decom_net_normal'):\n",
    "    normcc1 = tf.nn.conv2d(xnorm, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "        \n",
    "    normcc2 = tf.nn.conv2d(normcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    normconv2 = tf.nn.relu(normcc2 + b2, name=\"conv2\")        \n",
    "        \n",
    "    normcc3 = tf.nn.conv2d(normcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    normconv3 = tf.nn.relu(normcc3 + b3, name=\"conv3\")  \n",
    "        \n",
    "    normcc4 = tf.nn.conv2d(normcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    normconv4 = tf.nn.relu(normcc4 + b4, name=\"conv4\")  \n",
    "        \n",
    "    normcc5 = tf.nn.conv2d(normcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    normconv5 = tf.nn.relu(normcc5 + b5, name=\"conv5\")  \n",
    "        \n",
    "    normcc6 = tf.nn.conv2d(normcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    normconv6 = tf.nn.relu(normcc6 + b6, name=\"conv6\")  \n",
    "        \n",
    "    normcc7 = tf.nn.conv2d(normcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    normconv7 = tf.nn.sigmoid(normcc7 + b7, name=\"conv7\")  \n",
    "    print(\"normal conv7 shape:\",normconv7.shape)\n",
    "        \n",
    "with tf.name_scope('decom_output_low'):\n",
    "    Rlow = tf.slice(lowconv7,[0,0,0,0],[-1,-1,-1,3],name=\"Rlow_output\")   #output R low image\n",
    "    Ilow = tf.slice(lowconv7,[0,0,0,3],[-1,-1,-1,1],name='Ilow_output') #output I low image        \n",
    "    \n",
    "with tf.name_scope('decom_output_norm'):\n",
    "    Rnorm = tf.slice(normconv7,[0,0,0,0],[-1,-1,-1,3],name=\"Rnorm_output\")   #output R norm image\n",
    "    Inorm = tf.slice(normconv7,[0,0,0,3],[-1,-1,-1,1],name='Inorm_output') #output I norm image \n",
    "    print(\"Ilow shape:\",Ilow.shape)\n",
    "    print(\"Rlow shape:\",Rlow.shape)\n",
    "    print(\"Inorm shape:\",Inorm.shape)\n",
    "    print(\"Rnorm shape:\",Rnorm.shape) \n",
    "\n",
    "with tf.name_scope('enhance_net'):\n",
    "    with tf.name_scope(\"encoder_decoder\"):\n",
    "        pre_enh0 = tf.concat([Rlow,Ilow],axis=3) #concat on channel\n",
    "        pre_enh1 = tf.layers.conv2d(inputs=pre_enh0,filters=ek1,kernel_size=[3,3],padding='same', activation=None)   \n",
    "        encconv1  =  tf.layers.conv2d(inputs=pre_enh1,filters=ek1,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample1')\n",
    "        encconv2  =  tf.layers.conv2d(inputs=encconv1,filters=ek2,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample2')\n",
    "        encconv3  =  tf.layers.conv2d(inputs=encconv2,filters=ek3,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample3')\n",
    "        \n",
    "        #import types\n",
    "        #print(type(normconv7))\n",
    "        conv3_shape = encconv3.shape\n",
    "        upsample1 = tf.image.resize_nearest_neighbor(encconv3, (tf.shape(encconv2)[1],tf.shape(encconv2)[2]))\n",
    "        upconv1  =  tf.layers.conv2d(inputs=upsample1,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv1')\n",
    "        upresidual1 =  tf.add(upconv1,encconv2,name=\"upres1\")\n",
    "        \n",
    "        upresidual1_shape = upresidual1.shape\n",
    "        upsample2 = tf.image.resize_nearest_neighbor(upresidual1, (tf.shape(encconv1)[1],tf.shape(encconv1)[2]))\n",
    "        upconv2  =  tf.layers.conv2d(inputs=upsample2,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv2')\n",
    "        upresidual2 =  tf.add(upconv2,encconv1,name=\"upres2\")\n",
    "        \n",
    "        upresidual2_shape = upresidual2.shape\n",
    "        upsample3 = tf.image.resize_nearest_neighbor(upresidual2, (tf.shape(pre_enh1)[1],tf.shape(pre_enh1)[2]))\n",
    "        upconv3  =  tf.layers.conv2d(inputs=upsample3,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv3')\n",
    "        upresidual3 =  tf.add(upconv3,pre_enh1,name=\"upres3\")  \n",
    "        print(\"upresidual3 shape:\",upresidual3.shape)\n",
    "        \n",
    "    with tf.name_scope(\"upsample_concat\"):\n",
    "        upresidual3_shape = tf.shape(upresidual3)\n",
    "        preconcat1 = tf.image.resize_nearest_neighbor(upresidual1, (upresidual3_shape[1],upresidual3_shape[2])) \n",
    "        preconcat2 = tf.image.resize_nearest_neighbor(upresidual2, (upresidual3_shape[1],upresidual3_shape[2])) \n",
    "        preconcat3 = upresidual3\n",
    "        concat = tf.concat([preconcat1,preconcat2,preconcat3],axis=3)  #concat on channel direction\n",
    "        print(\"concat shape:\",concat.shape)\n",
    "        \n",
    "    with tf.name_scope('reconstruct_illumination'):\n",
    "        resizeconv = tf.layers.conv2d(inputs=concat,filters=rk,kernel_size=[1,1],strides=[1,1],padding='same',activation=None,name='resize_conv')\n",
    "        reconI = tf.layers.conv2d(inputs=resizeconv,filters=1,kernel_size=[3,3],strides=[1,1],padding='same',activation=None,name='reconstruct_illumination')\n",
    "        print(\"reconI shape:\",reconI.shape)\n",
    "        \n",
    "with tf.name_scope(\"reconstruct_Image\"):\n",
    "    denoiseR = Rlow\n",
    "    reconI_ex = tf.concat([reconI,reconI,reconI],axis=3)\n",
    "    reconImage = tf.multiply(reconI_ex,denoiseR,name=\"reconstruct_Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image gradient shape: 2\n",
      "Tensor(\"Reshape_18:0\", shape=(?, ?, ?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lamda00=1   \n",
    "lamda01=0.001\n",
    "lamda10=0.001\n",
    "lamda11=1\n",
    "lamda_g= -10\n",
    "lamda_ir = 0.01\n",
    "lamda_is = 0.1\n",
    "lamda_is_enh = 3\n",
    "\n",
    "##decom-net loss function\n",
    "Ilow_ex = tf.concat([Ilow,Ilow,Ilow],axis=3)\n",
    "Inorm_ex = tf.concat([Inorm,Inorm,Inorm],axis=3)\n",
    "xlow_image = tf.slice(xlow,[0,0,0,1],[-1,-1,-1,3])  #real image patch\n",
    "xnorm_image = tf.slice(xnorm,[0,0,0,1],[-1,-1,-1,3]) #real image patch\n",
    "\n",
    "Lrecon00 = tf.abs(tf.multiply(Ilow_ex,Rlow)-xlow_image)\n",
    "Lrecon01 = tf.abs(tf.multiply(Ilow_ex,Rnorm)-xlow_image)\n",
    "Lrecon10 = tf.abs(tf.multiply(Inorm_ex,Rlow)-xnorm_image)\n",
    "Lrecon11 = tf.abs(tf.multiply(Inorm_ex,Rnorm)-xnorm_image)\n",
    "Lrecon_decom = tf.reduce_mean(lamda00*Lrecon00+lamda01*Lrecon01+lamda10*Lrecon10+lamda11*Lrecon11)\n",
    "Lir_decom = tf.reduce_mean(tf.abs(Rlow-Rnorm))\n",
    "\n",
    "Rlow_gray = tf.image.rgb_to_grayscale(Rlow)\n",
    "Rnorm_gray = tf.image.rgb_to_grayscale(Rnorm) \n",
    "'''\n",
    "Lis_decom = tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[0])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[1])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[0])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[1]))\n",
    "'''\n",
    "Lis_decom = tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow)[0])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rlow_gray)[0]))) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow)[1])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rlow_gray)[1]))) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm)[0])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rnorm_gray)[0]))) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm)[1])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rnorm_gray)[1])))\n",
    "\n",
    "Ldecom = Lrecon_decom + lamda_ir*Lir_decom + lamda_is*Lis_decom\n",
    "print(\"image gradient shape:\",len(tf.image.image_gradients(Ilow_ex)))\n",
    "print(tf.image.image_gradients(Ilow_ex)[0])\n",
    "\n",
    "##enhance-net loss function\n",
    "Lrecon_enh = tf.reduce_mean(tf.abs(reconI_ex*denoiseR-xnorm_image))\n",
    "'''\n",
    "Lis_enh = tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[0])) + \\\n",
    "          tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[1]))\n",
    "'''\n",
    "Lis_enh = tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI)[0])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rlow_gray)[0]))) + \\\n",
    "          tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI)[1])*tf.exp(lamda_g*tf.abs(tf.image.image_gradients(Rlow_gray)[1])))\n",
    "\n",
    "Lenh = Lrecon_enh + lamda_is_enh*Lis_enh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.generate dataset and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low light file number: 1485\n",
      "norm light file number: 1485\n",
      "low file0 E:\\MyDownloads\\Download\\1006\\RetinexNet-master\\data\\our485\\low\\10.png\n",
      "norm file0 E:\\MyDownloads\\Download\\1006\\RetinexNet-master\\data\\our485\\high\\10.png\n"
     ]
    }
   ],
   "source": [
    "#get file name list\n",
    "low_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\low\\\\*.png\"\n",
    "norm_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\high\\\\*.png\"\n",
    "syn_low_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\syn\\\\low\\\\*.png\"\n",
    "syn_norm_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\syn\\\\high\\\\*.png\"\n",
    "low_names = tf.train.match_filenames_once(low_dir) #return all matched names, a variable\n",
    "norm_names = tf.train.match_filenames_once(norm_dir) \n",
    "syn_low_names = tf.train.match_filenames_once(syn_low_dir)\n",
    "syn_norm_names = tf.train.match_filenames_once(syn_norm_dir)\n",
    "low_list = tf.Variable(\"\",dtype=tf.string) \n",
    "norm_list = tf.Variable(\"\",dtype=tf.string) \n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    filesfind0,filesfind1,filesfind2,filesfind3 = sess.run((low_names,norm_names,syn_low_names,syn_norm_names))\n",
    "    low_string  = [\"\"]*(filesfind0.shape[0]+filesfind2.shape[0])\n",
    "    norm_string = [\"\"]*(filesfind1.shape[0]+filesfind3.shape[0])   \n",
    "    assert filesfind0.shape[0]==filesfind1.shape[0]\n",
    "    assert filesfind2.shape[0]==filesfind3.shape[0]\n",
    "    for i in range(0,filesfind0.shape[0]):\n",
    "        low_string[i]  = filesfind0[i].decode()  #from byte to string\n",
    "        norm_string[i] = filesfind1[i].decode()\n",
    "    for w in range(0,filesfind2.shape[0]):\n",
    "        low_string[filesfind0.shape[0]+w]  = filesfind2[w].decode()  #from byte to string\n",
    "        norm_string[filesfind0.shape[0]+w] = filesfind3[w].decode()    \n",
    "    low_list = low_string\n",
    "    norm_list = norm_string\n",
    "\n",
    "print(\"low light file number:\",len(low_list))\n",
    "print(\"norm light file number:\",len(norm_list))\n",
    "print(\"low file0\",low_list[0])\n",
    "print(\"norm file0\",norm_list[0])\n",
    "#im = np.asarray(Image.open(low_list[0]))/255.0\n",
    "#print(im)\n",
    "\n",
    "\n",
    "#build data set\n",
    "total_train_images = len(low_list)\n",
    "tr_data = tf.data.Dataset.from_tensor_slices((low_list,norm_list))   #buid dataset from file name\n",
    "tr_data = tr_data.map(input_parser_pair) #map file name to file\n",
    "tr_data = tr_data.shuffle(buffer_size=total_train_images).batch(batch).repeat(epoch) #form batch, pack 1 batch into 1 element\n",
    "#tr_data = tr_data.batch(batch).repeat(epoch)  #no shuffle\n",
    "\n",
    "#get iterator\n",
    "iterator = tr_data.make_initializable_iterator() #make iterator\n",
    "next_element = iterator.get_next()  #next batch actually\n",
    "training_init_op = iterator.make_initializer(tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.begin training\n",
    "Train Decom_Net for first half time; then train Enhance_Net for another half time with Decom_Net fixed.    \n",
    "During training, the input is image patches;\n",
    "During evaluation and testing, the input is 400*600 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each epoch contain batches: 99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.Session() as sess:\\n    # initialize the iterator on the training data\\n    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\\n    sess.run(training_init_op)\\n    train_writer = tf.summary.FileWriter(tboard, sess.graph)  #define summary writter\\n\\n    # get each element of the training dataset until the end is reached\\n    while True:\\n        try:  \\n            if(epoch_cycle < epoch/2):   #train decom-net\\n                elem = sess.run(next_element)  #get next batch input\\n                batch_cycle +=1\\n                all_batch +=1\\n                feed_train = {\\n                    imlow:elem[0],\\n                    imnorm:elem[1],\\n                    bypass_patch_gen:False\\n                }            \\n                sess.run(optimizer_decom,feed_dict=feed_train)\\n                \\n                if batch_cycle%10 == 0:\\n                    Ldecom_train = sess.run(Ldecom, feed_dict=feed_train)\\n                    print(\\'**train Decom-Net: loss for batch \\',batch_cycle,\" is \", Ldecom_train)\\n                    ##for TF-board\\n                    summary = sess.run(merged,feed_dict=feed_train)\\n                    train_writer.add_summary(summary,all_batch)\\n                \\n                if batch_cycle==total_batch:\\n                    batch_cycle =0\\n                    print(\"****end epoch:\",epoch_cycle)\\n                    epoch_cycle +=1\\n                    \\n                if (auto_checkpoint==1 and (epoch_cycle+1)%10 == 0 and epoch_cycle>0 and batch_cycle==total_batch-1):\\n                    feed_eval = {\\n                        imlow:elem[0],  \\n                        imnorm:elem[1],\\n                        bypass_patch_gen:True \\n                    }\\n                    print(\"******begin evaluate\")\\n                    Ilow_ex_train, Rlow_train = sess.run([Ilow_ex, Rlow], feed_dict=feed_eval) \\n                    save_decom = saver.save(sess,decom_checkpoint )  #save model\\n                    save_file = np.concatenate((elem[0][0:2],elem[1][0:2],Rlow_train, Ilow_ex_train), axis=2)\\n                    array_to_image(save_file,epoch_cycle,train_decom_path)\\n\\n                    \\n            else: # train enhance-net\\n                elem = sess.run(next_element)  #get next batch input\\n                batch_cycle +=1\\n                all_batch +=1\\n                feed_train = {\\n                    imlow:elem[0],\\n                    imnorm:elem[1],\\n                    bypass_patch_gen:False\\n                }            \\n                sess.run(optimizer_enh,feed_dict=feed_train)\\n                ##for TF-board\\n                summary = sess.run(merged,feed_dict=feed_train)\\n                train_writer.add_summary(summary,all_batch)\\n                \\n                if batch_cycle%10 == 0:\\n                    Lenh_train = sess.run(Lenh, feed_dict=feed_train)\\n                    print(\\'##train Enhance-Net: loss for batch \\',batch_cycle,\" is \", Lenh_train)\\n                    ##for TF-board\\n                    summary = sess.run(merged,feed_dict=feed_train)\\n                    train_writer.add_summary(summary,all_batch)\\n                    \\n                if batch_cycle==total_batch:\\n                    batch_cycle =0\\n                    print(\"####end epoch:\",int(epoch_cycle-epoch/2))  \\n                    epoch_cycle +=1\\n                    \\n                if (auto_checkpoint==1 and (epoch_cycle+1)%10 == 0 and epoch_cycle>0 and batch_cycle==total_batch-1):\\n                    feed_eval = {\\n                        imlow:elem[0],  \\n                        imnorm:elem[1],\\n                        bypass_patch_gen:True\\n                    }\\n                    print(\"######begin evaluate\")                    \\n                    reconImage_train, reconI_ex_train,Ilow_ex_train = sess.run([reconImage, reconI_ex,Ilow_ex], feed_dict=feed_eval)\\n                    save_enhance = saver.save(sess,enhance_checkpoint ) #save model  \\n                    save_decom = saver.save(sess,decom_checkpoint )  #save model\\n                    save_file = np.concatenate((elem[0][0:2],elem[1][0:2],Ilow_ex_train,reconI_ex_train, reconImage_train), axis=2)\\n                    array_to_image(save_file,int(epoch_cycle-epoch/2),train_enh_path)\\n\\n        except tf.errors.OutOfRangeError:\\n            print(\"End of training for Retinex-Net\")\\n            break  \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##run training\n",
    "decom_checkpoint = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\mycheckpoint\\\\decom\\\\\"\n",
    "enhance_checkpoint = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\mycheckpoint\\\\enhance\\\\\"\n",
    "train_decom_path = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\myresult\\\\train\\\\decom\\\\\"\n",
    "train_enh_path = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\myresult\\\\train\\\\enh\\\\\"\n",
    "test_result_path = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\myresult\\\\test\\\\\"\n",
    "tboard = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\mycheckpoint\\\\tboard\\\\\"\n",
    "variable_not_in_decom = [var for var in tf.trainable_variables() if 'decom' not in var.name]\n",
    "variable_in_decom = [var for var in tf.trainable_variables() if 'decom' in var.name]\n",
    "#optimizer_decom = tf.train.GradientDescentOptimizer(lr).minimize(Ldecom,var_list = variable_in_decom)\n",
    "#optimizer_enh = tf.train.GradientDescentOptimizer(lr).minimize(Lenh, var_list = variable_not_in_decom)\n",
    "optimizer_decom = tf.train.AdamOptimizer(lr).minimize(Ldecom,var_list = variable_in_decom)\n",
    "optimizer_enh = tf.train.AdamOptimizer(lr).minimize(Lenh, var_list = variable_not_in_decom)\n",
    "saver = tf.train.Saver()\n",
    "batch_cycle=0\n",
    "epoch_cycle=0\n",
    "all_batch = 0\n",
    "total_batch = 1485/batch\n",
    "print(\"each epoch contain batches:\",total_batch)\n",
    "\n",
    "'''#test dataset\n",
    "with tf.Session() as sess:\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(training_init_op)\n",
    "    elem = sess.run(next_element)\n",
    "    print(elem[0][0])\n",
    "'''\n",
    "\n",
    "##for TF-board\n",
    "dec_loss_summary = tf.summary.scalar('Decom_Loss', Ldecom)\n",
    "enh_loss_summary = tf.summary.scalar('Enhance_Loss', Lenh)\n",
    "Ilow_hist = tf.summary.histogram('Ilow', Ilow)\n",
    "reconI_hist = tf.summary.histogram('reconI', reconI)\n",
    "merged = tf.summary.merge([dec_loss_summary, enh_loss_summary,Ilow_hist,reconI_hist])\n",
    "\n",
    "'''\n",
    "with tf.Session() as sess:\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(training_init_op)\n",
    "    train_writer = tf.summary.FileWriter(tboard, sess.graph)  #define summary writter\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:  \n",
    "            if(epoch_cycle < epoch/2):   #train decom-net\n",
    "                elem = sess.run(next_element)  #get next batch input\n",
    "                batch_cycle +=1\n",
    "                all_batch +=1\n",
    "                feed_train = {\n",
    "                    imlow:elem[0],\n",
    "                    imnorm:elem[1],\n",
    "                    bypass_patch_gen:False\n",
    "                }            \n",
    "                sess.run(optimizer_decom,feed_dict=feed_train)\n",
    "                \n",
    "                if batch_cycle%10 == 0:\n",
    "                    Ldecom_train = sess.run(Ldecom, feed_dict=feed_train)\n",
    "                    print('**train Decom-Net: loss for batch ',batch_cycle,\" is \", Ldecom_train)\n",
    "                    ##for TF-board\n",
    "                    summary = sess.run(merged,feed_dict=feed_train)\n",
    "                    train_writer.add_summary(summary,all_batch)\n",
    "                \n",
    "                if batch_cycle==total_batch:\n",
    "                    batch_cycle =0\n",
    "                    print(\"****end epoch:\",epoch_cycle)\n",
    "                    epoch_cycle +=1\n",
    "                    \n",
    "                if (auto_checkpoint==1 and (epoch_cycle+1)%10 == 0 and epoch_cycle>0 and batch_cycle==total_batch-1):\n",
    "                    feed_eval = {\n",
    "                        imlow:elem[0],  \n",
    "                        imnorm:elem[1],\n",
    "                        bypass_patch_gen:True \n",
    "                    }\n",
    "                    print(\"******begin evaluate\")\n",
    "                    Ilow_ex_train, Rlow_train = sess.run([Ilow_ex, Rlow], feed_dict=feed_eval) \n",
    "                    save_decom = saver.save(sess,decom_checkpoint )  #save model\n",
    "                    save_file = np.concatenate((elem[0][0:2],elem[1][0:2],Rlow_train, Ilow_ex_train), axis=2)\n",
    "                    array_to_image(save_file,epoch_cycle,train_decom_path)\n",
    "\n",
    "                    \n",
    "            else: # train enhance-net\n",
    "                elem = sess.run(next_element)  #get next batch input\n",
    "                batch_cycle +=1\n",
    "                all_batch +=1\n",
    "                feed_train = {\n",
    "                    imlow:elem[0],\n",
    "                    imnorm:elem[1],\n",
    "                    bypass_patch_gen:False\n",
    "                }            \n",
    "                sess.run(optimizer_enh,feed_dict=feed_train)\n",
    "                ##for TF-board\n",
    "                summary = sess.run(merged,feed_dict=feed_train)\n",
    "                train_writer.add_summary(summary,all_batch)\n",
    "                \n",
    "                if batch_cycle%10 == 0:\n",
    "                    Lenh_train = sess.run(Lenh, feed_dict=feed_train)\n",
    "                    print('##train Enhance-Net: loss for batch ',batch_cycle,\" is \", Lenh_train)\n",
    "                    ##for TF-board\n",
    "                    summary = sess.run(merged,feed_dict=feed_train)\n",
    "                    train_writer.add_summary(summary,all_batch)\n",
    "                    \n",
    "                if batch_cycle==total_batch:\n",
    "                    batch_cycle =0\n",
    "                    print(\"####end epoch:\",int(epoch_cycle-epoch/2))  \n",
    "                    epoch_cycle +=1\n",
    "                    \n",
    "                if (auto_checkpoint==1 and (epoch_cycle+1)%10 == 0 and epoch_cycle>0 and batch_cycle==total_batch-1):\n",
    "                    feed_eval = {\n",
    "                        imlow:elem[0],  \n",
    "                        imnorm:elem[1],\n",
    "                        bypass_patch_gen:True\n",
    "                    }\n",
    "                    print(\"######begin evaluate\")                    \n",
    "                    reconImage_train, reconI_ex_train,Ilow_ex_train = sess.run([reconImage, reconI_ex,Ilow_ex], feed_dict=feed_eval)\n",
    "                    save_enhance = saver.save(sess,enhance_checkpoint ) #save model  \n",
    "                    save_decom = saver.save(sess,decom_checkpoint )  #save model\n",
    "                    save_file = np.concatenate((elem[0][0:2],elem[1][0:2],Ilow_ex_train,reconI_ex_train, reconImage_train), axis=2)\n",
    "                    array_to_image(save_file,int(epoch_cycle-epoch/2),train_enh_path)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training for Retinex-Net\")\n",
    "            break  \n",
    "'''          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\MyDownloads\\Download\\1006\\RetinexNet-master\\mycheckpoint\\enhance\\\n",
      "Model restored.\n",
      "(4, 618, 464, 3)\n",
      "(4, 618, 464, 3)\n",
      "test done!\n"
     ]
    }
   ],
   "source": [
    "#load saved model or test with current model\n",
    "testface = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\MyTestFace_small\\\\\"\n",
    "\n",
    "testim0 = np.asarray(Image.open(os.path.join(testface,\"IMG_2977.jpg\")))/255.0\n",
    "testim1 = np.asarray(Image.open(os.path.join(testface,\"IMG_2993.jpg\")))/255.0\n",
    "testim2 = np.asarray(Image.open(os.path.join(testface,\"IMG_3017.jpg\")))/255.0\n",
    "testim3 = np.asarray(Image.open(os.path.join(testface,\"IMG_3030.jpg\")))/255.0\n",
    "testim = np.stack((testim0,testim1,testim2,testim3),axis=0) #concatenate as batch\n",
    "\n",
    "\n",
    "if load_pretrain==1:\n",
    "    with tf.Session() as sess:\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, enhance_checkpoint)\n",
    "        print(\"Model restored.\") \n",
    "        #several images\n",
    "        feed_test = {\n",
    "                imlow: testim, \n",
    "                imnorm: testim,\n",
    "                bypass_patch_gen:True\n",
    "        }\n",
    "        reconImage_test = sess.run(reconImage, feed_dict=feed_test)\n",
    "        print(testim.shape)\n",
    "        print(reconImage_test.shape)\n",
    "        save_test = np.concatenate((testim,reconImage_test), axis=2)\n",
    "        array_to_image(save_test,100,test_result_path)  \n",
    "        print(\"test done!\")\n",
    "else:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
