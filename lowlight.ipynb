{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low light face enhancement with Retinex-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#this project is for low light face enhancement\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all parameters\n",
    "seed = 2018\n",
    "patch = 48 \n",
    "lr = 0.01 #learning rate\n",
    "batch = 5 #batch number, better a factor of total image number\n",
    "epoch = 1\n",
    "dk1 = 64 #decom-net kernel number for conv1\n",
    "dk2 = 64\n",
    "dk3 = 64\n",
    "dk4 = 64\n",
    "dk5 = 64\n",
    "dk6 = 64\n",
    "dk7 = 4\n",
    "\n",
    "ek1 = 64 #enhance-net kernel number for conv1\n",
    "ek2 = 64\n",
    "ek3 = 64\n",
    "rk = 64 #resize layer kernel numebr\n",
    "\n",
    "lamda00=1   \n",
    "lamda01=0.01\n",
    "lamda10=0.01\n",
    "lamda11=1\n",
    "lamda_g= -10\n",
    "lamda_ir = 0.001\n",
    "lamda_is = 0.1\n",
    "lamda_is_enh = 3\n",
    "random.seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.define local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "    target = tf.image.resize_nearest_neighbor(source, (newHt,newWid))\n",
    "    return target\n",
    "\n",
    "'''\n",
    "def nearestNeighborScaling4D( source, newHt,newWid):\n",
    "     #souce: 4D tensor, 4D=[batch,height,width,channel]\n",
    "     #newHt: target Height\n",
    "     #newWid: target Width\n",
    "    width  = int(source.shape[2])\n",
    "    height = int(source.shape[1])\n",
    "    print(\"source shape:\",source.shape)    \n",
    "    newX = tf.Variable(tf.zeros(shape=[source.shape[0],newHt+1,1,source.shape[-1]]), name=\"tempX\")\n",
    "    for x in range(0, newWid):  \n",
    "        newY = tf.Variable(tf.zeros(shape=[source.shape[0],1,1,source.shape[-1]]), name=\"tempY\")        \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            sourceSlice = tf.slice(source,[0,srcY,srcX,0],[source.shape[0],1,1,source.shape[-1]])\n",
    "            newY = tf.concat([newY,sourceSlice],axis=1)\n",
    "        newX = tf.concat([newX,newY],axis=2)\n",
    "    target = tf.slice(newX,[0,1,1,0],[source.shape[0],newHt,newWid,source.shape[-1]])\n",
    "    print(\"target shape:\",target.shape)\n",
    "    return target\n",
    "'''\n",
    "\n",
    "def nearestNeighborScaling3D( source, newHt,newWid):\n",
    "    '''\n",
    "     souce: 3D array, 3D=[height,width,channel]\n",
    "     newHt: target Height\n",
    "     newWid: target Width\n",
    "    '''\n",
    "    width  = int(source.shape[1])\n",
    "    height = int(source.shape[0])\n",
    "    target = np.zeros((newHt,newWid,source.shape[-1]),dtype = np.float32)\n",
    "    for x in range(0, newWid):  \n",
    "        for y in range(0, newHt):\n",
    "            srcX = int( round( float(x) / float(newWid) * float(width) ) )\n",
    "            srcY = int( round( float(y) / float(newHt) * float(height) ) )\n",
    "            srcX = min( srcX, width-1)\n",
    "            srcY = min( srcY, height-1)\n",
    "            target[y,x,:] = source[srcY,srcX,:]\n",
    "    return target\n",
    "\n",
    "# random data augmentation\n",
    "def data_aug(image0, image1):\n",
    "    #total 4*2*2 = 16 choice\n",
    "    mode = np.random.randint(2,size=3)   #mode is an array, 3 elements\n",
    "    rotate = random.randint(0,3)\n",
    "    new_image0 = image0\n",
    "    new_image1 = image1\n",
    "    if mode[0]==1:  #rotate 0/90/180/270\n",
    "        new_image0 = tf.image.rot90(new_image0,k=rotate)\n",
    "        new_image1 = tf.image.rot90(new_image0,k=rotate)\n",
    "    if mode[1]==1: #flip left/right\n",
    "        new_image0 = tf.image.flip_left_right(new_image0)\n",
    "        new_image1 = tf.image.flip_left_right(new_image1)\n",
    "    if mode[2]==1:  #flip up/down\n",
    "        new_image0 = tf.image.flip_up_down(new_image0)\n",
    "        new_image1 = tf.image.flip_up_down(new_image1)\n",
    "    return new_image0,new_image1 \n",
    "\n",
    "#generate random patch with data augmentation\n",
    "def patch_gen(image0,image1):\n",
    "    imh = int(image0.shape[1])\n",
    "    imw = int(image0.shape[2])\n",
    "    image0_patch = tf.Variable(tf.zeros(shape=[1,patch,patch,3]), name=\"image_patch0\")\n",
    "    image1_patch = tf.Variable(tf.zeros(shape=[1,patch,patch,3]), name=\"image_patch1\")\n",
    "    for i in range(batch):\n",
    "        randh = random.randint(0,imh-patch)\n",
    "        randw = random.randint(0,imw-patch)\n",
    "        image0_temp = tf.slice(image0,[i,randh,randw,0],[1,patch,patch,-1]) #get slice\n",
    "        image1_temp = tf.slice(image1,[i,randh,randw,0],[1,patch,patch,-1])\n",
    "        image0_temp,image1_temp = data_aug(image0_temp,image1_temp) #dat sugmentation\n",
    "        image0_patch = tf.concat([image0_patch,image0_temp],axis=0)\n",
    "        image1_patch = tf.concat([image1_patch,image1_temp],axis=0)\n",
    "    image0_patch = tf.slice(image0_patch,[1,0,0,0],[-1,-1,-1,-1])\n",
    "    image1_patch = tf.slice(image1_patch,[1,0,0,0],[-1,-1,-1,-1])\n",
    "    return image0_patch,image1_patch\n",
    "\n",
    "#extend channel form 3 to 4, by adding max_in_channel\n",
    "def channel_extension(image0,image1):\n",
    "    image0_ex = tf.reduce_max(image0, axis=3, keepdims=True)\n",
    "    image1_ex = tf.reduce_max(image1, axis=3, keepdims=True)\n",
    "    image0_new = tf.concat([image0_ex,image0],axis=3)  ##?? the sequence?\n",
    "    image1_new = tf.concat([image1_ex,image1],axis=3)\n",
    "    return image0_new,image1_new\n",
    "    \n",
    "\n",
    "#from original image pair --> input image pair\n",
    "def input_parser_pair(img_path0,img_path1):\n",
    "    # read the img from file\n",
    "    img_file0 = tf.read_file(img_path0)\n",
    "    img_file1 = tf.read_file(img_path1)\n",
    "    img_decoded0 = tf.image.decode_image(img_file0,dtype=tf.float32, channels=3) #3D tensor\n",
    "    img_decoded1 = tf.image.decode_image(img_file1,dtype=tf.float32, channels=3)\n",
    "    image_stack0 = tf.stack([img_decoded0],axis=0) #3D->4D\n",
    "    image_stack1 = tf.stack([img_decoded1],axis=0)\n",
    "    img0_resize = tf.image.resize_nearest_neighbor(image_stack0,[400,600]) #only support 4D input\n",
    "    img1_resize = tf.image.resize_nearest_neighbor(image_stack1,[400,600])\n",
    "    img0_resize_3D = (tf.squeeze(img0_resize))/255.0 #4D->3D\n",
    "    img1_resize_3D = (tf.squeeze(img0_resize))/255.0\n",
    "    return img0_resize_3D,img1_resize_3D\n",
    "    ''' \n",
    "    image_stack0 = tf.stack([img_decoded0],axis=0) #3D->4D\n",
    "    image_stack1 = tf.stack([img_decoded1],axis=0)\n",
    "    print(\"image_stack0 shape:\",image_stack0.shape)\n",
    "    image_patch0 = tf.image.extract_image_patches(image_stack0,ksizes=[1,patch,patch,1],strides=[1,patch,patch,1],rates=[1,1,1,1],padding=\"VALID\")\n",
    "    image_patch1 = tf.image.extract_image_patches(image_stack1,ksizes=[1,patch,patch,1],strides=[1,patch,patch,1],rates=[1,1,1,1],padding=\"VALID\")\n",
    "    return image_patch0,image_patch1    \n",
    "    '''\n",
    "    #return img_decoded0,img_decoded1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low conv1 shape: (5, 48, 48, 64)\n",
      "low conv7 shape: (5, 48, 48, 4)\n",
      "normal conv7 shape: (5, 48, 48, 4)\n",
      "Ilow shape: (5, 48, 48, 1)\n",
      "Rlow shape: (5, 48, 48, 3)\n",
      "Inorm shape: (5, 48, 48, 1)\n",
      "Rnorm shape: (5, 48, 48, 3)\n",
      "upresidual3 shape: (5, 48, 48, 64)\n",
      "concat shape: (5, 48, 48, 192)\n",
      "reconI shape: (5, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#build network\n",
    "with tf.name_scope('input_image'):\n",
    "    imlow = tf.placeholder(tf.float32, shape=[batch,400,600,3],name = 'input_low')   #input low light image\n",
    "    imnorm = tf.placeholder(tf.float32, shape=[batch,400,600,3], name='input_norm') #input norm light image\n",
    "    xlow_pre, xnorm_pre = patch_gen(imlow,imnorm)  #generate patch with data augmentation\n",
    "    xlow, xnorm = channel_extension(xlow_pre,xnorm_pre) #channel extention 3->4 \n",
    "\n",
    "'''\n",
    "with tf.name_scope('input_image'):\n",
    "    imlow = tf.placeholder(tf.float32, shape=[batch,patch,patch,3],name = 'input_low')   #input low light image\n",
    "    imnorm = tf.placeholder(tf.float32, shape=[batch,patch,patch,3], name='input_norm') #input norm light image\n",
    "    xlow, xnorm = channel_extension(imlow,imnorm) #channel extention 3->4\n",
    "'''        \n",
    "with tf.variable_scope(\"decom\", reuse=tf.AUTO_REUSE):  #define weight and bias\n",
    "    #shared weight between low light Decom-net and normal light Decom-net\n",
    "    weight1 = tf.get_variable(name='w1', shape=[3,3,4,dk1],  initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight2 = tf.get_variable(name='w2', shape=[3,3,dk1,dk2], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight3 = tf.get_variable(name='w3', shape=[3,3,dk2,dk3],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight4 = tf.get_variable(name='w4', shape=[3,3,dk3,dk4],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight5 = tf.get_variable(name='w5', shape=[3,3,dk4,dk5],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight6 = tf.get_variable(name='w6', shape=[3,3,dk5,dk6],initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    weight7 = tf.get_variable(name='w7', shape=[3,3,dk6,dk7], initializer=tf.contrib.layers.xavier_initializer_conv2d(), dtype=tf.float32)\n",
    "    #bias for low light conv\n",
    "    lowb1 = tf.get_variable(\"lowb1\", shape=[dk1], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb2 = tf.get_variable(\"lowb2\", shape=[dk2], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb3 = tf.get_variable(\"lowb3\", shape=[dk3], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb4 = tf.get_variable(\"lowb4\", shape=[dk4], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb5 = tf.get_variable(\"lowb5\", shape=[dk5], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb6 = tf.get_variable(\"lowb6\", shape=[dk6], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    lowb7 = tf.get_variable(\"lowb7\", shape=[dk7], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    #bias for normal light conv\n",
    "    normb1 = tf.get_variable(\"normb1\", shape=[dk1], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb2 = tf.get_variable(\"normb2\", shape=[dk2], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb3 = tf.get_variable(\"normb3\", shape=[dk3], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb4 = tf.get_variable(\"normb4\", shape=[dk4], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb5 = tf.get_variable(\"normb5\", shape=[dk5], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb6 = tf.get_variable(\"normb6\", shape=[dk6], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "    normb7 = tf.get_variable(\"normb7\", shape=[dk7], initializer=tf.constant_initializer(0.01), dtype=tf.float32)\n",
    "        \n",
    "with tf.name_scope('decom_net_low'):\n",
    "    lowcc1 = tf.nn.conv2d(xlow, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "    lowconv1 = tf.add(lowcc1,lowb1, name=\"conv1\")   #no activation funciton\n",
    "    print(\"low conv1 shape:\",lowconv1.shape)\n",
    "        \n",
    "    lowcc2 = tf.nn.conv2d(lowcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    lowconv2 = tf.nn.relu(lowcc2 + lowb2, name=\"conv2\")        \n",
    "    #print(\"low conv2 shape:\",lowconv2.shape)\n",
    "            \n",
    "    lowcc3 = tf.nn.conv2d(lowcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    lowconv3 = tf.nn.relu(lowcc3 + lowb3, name=\"conv3\")  \n",
    "    #print(\"low conv3 shape:\",lowconv3.shape)\n",
    "        \n",
    "    lowcc4 = tf.nn.conv2d(lowcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    lowconv4 = tf.nn.relu(lowcc4 + lowb4, name=\"conv4\")  \n",
    "    #print(\"low conv4 shape:\",lowconv4.shape) \n",
    "\n",
    "    lowcc5 = tf.nn.conv2d(lowcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    lowconv5 = tf.nn.relu(lowcc5 + lowb5, name=\"conv5\")  \n",
    "    #print(\"low conv5 shape:\",lowconv5.shape)\n",
    "        \n",
    "    lowcc6 = tf.nn.conv2d(lowcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    lowconv6 = tf.nn.relu(lowcc6 + lowb6, name=\"conv6\")  \n",
    "    #print(\"low conv6 shape:\",lowconv6.shape)\n",
    "        \n",
    "    lowcc7 = tf.nn.conv2d(lowcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    lowconv7 = tf.nn.sigmoid(lowcc7 + lowb7, name=\"conv7\") \n",
    "    print(\"low conv7 shape:\",lowconv7.shape)\n",
    "\n",
    "with tf.name_scope('decom_net_normal'):\n",
    "    normcc1 = tf.nn.conv2d(xnorm, weight1, strides=[1,1,1,1], padding='SAME', name=\"cc1\")\n",
    "    normconv1 = tf.nn.relu(normcc1 + normb1, name=\"conv1\")\n",
    "        \n",
    "    normcc2 = tf.nn.conv2d(normcc1, weight2, strides=[1,1,1,1], padding='SAME', name=\"cc2\")\n",
    "    normconv2 = tf.nn.relu(normcc2 + normb2, name=\"conv2\")        \n",
    "        \n",
    "    normcc3 = tf.nn.conv2d(normcc2, weight3, strides=[1,1,1,1], padding='SAME', name=\"cc3\")\n",
    "    normconv3 = tf.nn.relu(normcc3 + normb3, name=\"conv3\")  \n",
    "        \n",
    "    normcc4 = tf.nn.conv2d(normcc3, weight4, strides=[1,1,1,1], padding='SAME', name=\"cc4\")\n",
    "    normconv4 = tf.nn.relu(normcc4 + normb4, name=\"conv4\")  \n",
    "        \n",
    "    normcc5 = tf.nn.conv2d(normcc4, weight5, strides=[1,1,1,1], padding='SAME', name=\"cc5\")\n",
    "    normconv5 = tf.nn.relu(normcc5 + normb5, name=\"conv5\")  \n",
    "        \n",
    "    normcc6 = tf.nn.conv2d(normcc5, weight6, strides=[1,1,1,1], padding='SAME', name=\"cc6\")\n",
    "    normconv6 = tf.nn.relu(normcc6 + normb6, name=\"conv6\")  \n",
    "        \n",
    "    normcc7 = tf.nn.conv2d(normcc6, weight7, strides=[1,1,1,1], padding='SAME', name=\"cc7\")\n",
    "    normconv7 = tf.nn.sigmoid(normcc7 + normb7, name=\"conv7\")  \n",
    "    print(\"normal conv7 shape:\",normconv7.shape)\n",
    "        \n",
    "with tf.name_scope('decom_output_low'):\n",
    "    Rlow = tf.slice(lowconv7,[0,0,0,0],[batch,-1,-1,3],name=\"Rlow_output\")   #output R low image\n",
    "    Ilow = tf.slice(lowconv7,[0,0,0,3],[batch,-1,-1,1],name='Ilow_output') #output I low image        \n",
    "    \n",
    "with tf.name_scope('decom_output_norm'):\n",
    "    Rnorm = tf.slice(normconv7,[0,0,0,0],[batch,-1,-1,3],name=\"Rnorm_output\")   #output R norm image\n",
    "    Inorm = tf.slice(normconv7,[0,0,0,3],[batch,-1,-1,1],name='Inorm_output') #output I norm image \n",
    "    print(\"Ilow shape:\",Ilow.shape)\n",
    "    print(\"Rlow shape:\",Rlow.shape)\n",
    "    print(\"Inorm shape:\",Inorm.shape)\n",
    "    print(\"Rnorm shape:\",Rnorm.shape) \n",
    "\n",
    "with tf.name_scope('enhance_net'):\n",
    "    with tf.name_scope(\"encoder_decoder\"):\n",
    "        pre_enh = tf.concat([Rlow,Ilow],axis=3) #concat on channel\n",
    "        pre_enh = tf.layers.conv2d(inputs=pre_enh,filters=ek1,kernel_size=[3,3],padding='same', activation=None)   \n",
    "        encconv1  =  tf.layers.conv2d(inputs=pre_enh,filters=ek1,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample1')\n",
    "        encconv2  =  tf.layers.conv2d(inputs=encconv1,filters=ek2,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample2')\n",
    "        encconv3  =  tf.layers.conv2d(inputs=encconv2,filters=ek3,kernel_size=[3,3],strides=[2,2],padding='same',activation=tf.nn.relu,name='downsample3')\n",
    "        \n",
    "        #import types\n",
    "        #print(type(normconv7))\n",
    "        conv3_shape = encconv3.shape\n",
    "        upsample1 = nearestNeighborScaling4D(encconv3, int(conv3_shape[1]*2),int(conv3_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv1  =  tf.layers.conv2d(inputs=upsample1,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv1')\n",
    "        upresidual1 =  tf.add(upconv1,encconv2,name=\"upres1\")\n",
    "        \n",
    "        upresidual1_shape = upresidual1.shape\n",
    "        upsample2 = nearestNeighborScaling4D(upresidual1, int(upresidual1_shape[1]*2),int(upresidual1_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv2  =  tf.layers.conv2d(inputs=upsample2,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv2')\n",
    "        upresidual2 =  tf.add(upconv2,encconv1,name=\"upres2\")\n",
    "        \n",
    "        upresidual2_shape = upresidual2.shape\n",
    "        upsample3 = nearestNeighborScaling4D(upresidual2, int(upresidual2_shape[1]*2),int(upresidual2_shape[2]*2))  #upsample,W*2,H*2 \n",
    "        upconv3  =  tf.layers.conv2d(inputs=upsample3,filters=ek1,kernel_size=[3,3],strides=[1,1],padding='same',activation=tf.nn.relu,name='upconv3')\n",
    "        upresidual3 =  tf.add(upconv3,Ilow,name=\"upres3\")  \n",
    "        print(\"upresidual3 shape:\",upresidual3.shape)\n",
    "        \n",
    "    with tf.name_scope(\"upsample_concat\"):\n",
    "        upresidual3_shape = upresidual3.shape\n",
    "        preconcat1 = nearestNeighborScaling4D(upresidual1, int(upresidual3_shape[1]),int(upresidual3_shape[2])) \n",
    "        preconcat2 = nearestNeighborScaling4D(upresidual2, int(upresidual3_shape[1]),int(upresidual3_shape[2])) \n",
    "        preconcat3 = upresidual3\n",
    "        concat = tf.concat([preconcat1,preconcat2,preconcat3],axis=3)  #concat on channel direction\n",
    "        print(\"concat shape:\",concat.shape)\n",
    "        \n",
    "    with tf.name_scope('reconstruct_illumination'):\n",
    "        resizeconv = tf.layers.conv2d(inputs=concat,filters=rk,kernel_size=[1,1],strides=[1,1],padding='same',activation=None,name='resize_conv')\n",
    "        reconI = tf.layers.conv2d(inputs=resizeconv,filters=1,kernel_size=[3,3],strides=[1,1],padding='same',activation=None,name='reconstruct_illumination')\n",
    "        print(\"reconI shape:\",reconI.shape)\n",
    "        \n",
    "with tf.name_scope(\"reconstruct_Image\"):\n",
    "    denoiseR = Rlow\n",
    "    reconI_ex = tf.concat([reconI,reconI,reconI],axis=3)\n",
    "    reconImage = tf.multiply(reconI_ex,denoiseR,name=\"reconstruct_Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decom-net loss function\n",
    "Ilow_ex = tf.concat([Ilow,Ilow,Ilow],axis=3)\n",
    "Inorm_ex = tf.concat([Inorm,Inorm,Inorm],axis=3)\n",
    "xlow_image = tf.slice(xlow,[0,0,0,1],[-1,-1,-1,3])  #real image patch\n",
    "xnorm_image = tf.slice(xnorm,[0,0,0,1],[-1,-1,-1,3]) #real image patch\n",
    "\n",
    "Lrecon00 = tf.abs(tf.multiply(Ilow_ex,Rlow)-xlow_image)\n",
    "Lrecon01 = tf.abs(tf.multiply(Ilow_ex,Rnorm)-xlow_image)\n",
    "Lrecon10 = tf.abs(tf.multiply(Inorm_ex,Rlow)-xnorm_image)\n",
    "Lrecon11 = tf.abs(tf.multiply(Inorm_ex,Rnorm)-xnorm_image)\n",
    "Lrecon_decom = tf.reduce_mean(lamda00*Lrecon00+lamda01*Lrecon01+lamda10*Lrecon10+lamda11*Lrecon11)\n",
    "Lir_decom = tf.reduce_mean(tf.abs(Rlow-Rnorm))\n",
    "\n",
    "Lis_decom = tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[0])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Ilow_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(Rlow)[1])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[0])) + \\\n",
    "            tf.reduce_mean(tf.abs(tf.image.image_gradients(Inorm_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(Rnorm)[1]))\n",
    "Ldecom = Lrecon_decom + lamda_ir*Lir_decom + lamda_is*Lis_decom\n",
    "\n",
    "\n",
    "##enhance-net loss function\n",
    "Lrecon_enh = tf.reduce_mean(reconI_ex*denoiseR-xnorm_image)\n",
    "Lis_enh = tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI_ex)[0])*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[0])) + \\\n",
    "          tf.reduce_mean(tf.abs(tf.image.image_gradients(reconI_ex)[1])*tf.exp(lamda_g*tf.image.image_gradients(denoiseR)[1]))\n",
    "Lenh = Lrecon_enh + lamda_is_enh*Lis_enh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.generate dataset and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low light file number: 1485\n",
      "norm light file number: 1485\n"
     ]
    }
   ],
   "source": [
    "#get file name list\n",
    "low_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\low\\\\*.png\"\n",
    "norm_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\our485\\\\high\\\\*.png\"\n",
    "syn_low_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\syn\\\\low\\\\*.png\"\n",
    "syn_norm_dir = \"E:\\\\MyDownloads\\\\Download\\\\1006\\\\RetinexNet-master\\\\data\\\\syn\\\\high\\\\*.png\"\n",
    "low_names = tf.train.match_filenames_once(low_dir) #return all matched names, a variable\n",
    "norm_names = tf.train.match_filenames_once(norm_dir) \n",
    "syn_low_names = tf.train.match_filenames_once(syn_low_dir)\n",
    "syn_norm_names = tf.train.match_filenames_once(syn_norm_dir)\n",
    "low_list = tf.Variable(\"\",dtype=tf.string) \n",
    "norm_list = tf.Variable(\"\",dtype=tf.string) \n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    filesfind0,filesfind1,filesfind2,filesfind3 = sess.run((low_names,norm_names,syn_low_names,syn_norm_names))\n",
    "    low_string  = [\"\"]*(filesfind0.shape[0]+filesfind2.shape[0])\n",
    "    norm_string = [\"\"]*(filesfind1.shape[0]+filesfind2.shape[0])   \n",
    "    assert filesfind0.shape[0]==filesfind1.shape[0]\n",
    "    assert filesfind2.shape[0]==filesfind3.shape[0]\n",
    "    for i in range(0,filesfind0.shape[0]):\n",
    "        low_string[i]  = filesfind0[i].decode()  #from byte to string\n",
    "        norm_string[i] = filesfind1[i].decode()\n",
    "    for w in range(0,filesfind2.shape[0]):\n",
    "        low_string[filesfind0.shape[0]+w]  = filesfind2[w].decode()  #from byte to string\n",
    "        norm_string[filesfind0.shape[0]+w] = filesfind3[w].decode()    \n",
    "    low_list = low_string\n",
    "    norm_list = norm_string\n",
    "\n",
    "print(\"low light file number:\",len(low_list))\n",
    "print(\"norm light file number:\",len(norm_list))\n",
    "\n",
    "#build data set\n",
    "total_train_images = len(low_list)\n",
    "tr_data = tf.data.Dataset.from_tensor_slices((low_list,norm_list))   #buid dataset from file name\n",
    "tr_data = tr_data.map(input_parser_pair) #map file name to file\n",
    "tr_data = tr_data.shuffle(buffer_size=total_train_images).batch(batch).repeat(epoch) #form batch, pack 1 batch into 1 element\n",
    "\n",
    "#get iterator\n",
    "iterator = tr_data.make_initializable_iterator() #make iterator\n",
    "next_element = iterator.get_next()  #next batch actually\n",
    "training_init_op = iterator.make_initializer(tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.begin training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 train decom-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** begin to train Decom Net ***********\n",
      "loss for batch  200  is  0.42809084\n",
      "epoch: 1\n",
      "End of training for DecomNet.\n"
     ]
    }
   ],
   "source": [
    "print(\"******** begin to train Decom Net ***********\")\n",
    "##run training\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(Ldecom)\n",
    "i=0\n",
    "j=0\n",
    "with tf.Session() as sess:\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            i +=1\n",
    "            elem = sess.run(next_element)  #get next batch input image\n",
    "            feed = {\n",
    "                imlow:elem[0],\n",
    "                imnorm:elem[1]\n",
    "            }            \n",
    "            sess.run(optimizer,feed_dict=feed)\n",
    "            if i%(1485/5)==0:\n",
    "                j +=1\n",
    "                print(\"epoch:\",j)\n",
    "            if i%200 == 0:\n",
    "                print('loss for batch ',i,\" is \", sess.run(Ldecom, feed_dict=feed))\n",
    "            if j%20 == 0:\n",
    "                ## fixme: add save \n",
    "                pass\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training for DecomNet.\")\n",
    "            break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 train enhance net\n",
    "fix decom-net weight, only train enhance net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** begin to train Enhance Net ***********\n",
      "loss for batch  200  is  nan\n",
      "epoch: 1\n",
      "End of training for DecomNet.\n"
     ]
    }
   ],
   "source": [
    "print(\"******** begin to train Enhance Net ***********\")\n",
    "variable_not_in_decom = [var for var in tf.trainable_variables() if 'decom' not in var.name]\n",
    "#print(variable_not_in_decom)\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(Lenh, var_list = variable_not_in_decom)\n",
    "i=0\n",
    "j=0\n",
    "with tf.Session() as sess:\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))   \n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            i +=1\n",
    "            elem = sess.run(next_element)  #get next batch input image\n",
    "            feed = {\n",
    "                imlow:elem[0],\n",
    "                imnorm:elem[1]\n",
    "            }            \n",
    "            sess.run(optimizer,feed_dict=feed)\n",
    "            if i%(1485/5)==0:\n",
    "                j +=1\n",
    "                print(\"epoch:\",j)\n",
    "            if i%200 == 0:\n",
    "                print('loss for batch ',i,\" is \", sess.run(Lenh, feed_dict=feed))\n",
    "            if j%20 == 0:\n",
    "                ## fixme: add save \n",
    "                pass\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training for DecomNet.\")\n",
    "            break      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
